---
title: "cleaning data"
author: "Thomas Delcey"
date: '2022-06-27'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

-   [1 What is this script for?](#what-is-this-script-for)
-   [2 Loading packages, paths and data](#loading-packages-paths-and-data)
- [3 Featurization](#Featurization)
- [4 DTM](#DTM)
- [5 Finding k](#Finding k)
- [6 Topic Model](#Topic Model)

# 1 What is this script for?


# 2 Loading packages, paths and
    data
    
```{r, message=FALSE, echo=FALSE}

source("C:/Users/thomd/Documents/MEGA/github/ANR/script/0_paths_and_packages.R")

dos_partenaire_df <- readRDS(paste0(data_path, "dos_partenaire_df.RDS"))
dos_projet_df <- readRDS(paste0(data_path, "dos_projet_df.RDS"))

```

#Featurization
```{r}
library(sotu)
library(tidytext)
library(SnowballC) 
library(ldatuning)

library("textcat")

summary <- dos_projet_df %>%
   filter(!is.na(text)) %>% #filter projet with an english summary
   select(c(id, text, year)) %>% #renames variables 
   unnest_tokens(output = token, input = text) %>%
   anti_join(get_stopwords(), by = c("token" = "word")) %>% # stop word
   anti_join(get_stopwords(language = "fr"), by = c("token" = "word")) %>% # stop word
   mutate(token = wordStem(token, language = "en")) #stemming



library(qdapDictionaries)

is.word  <- function(x) x %in% GradyAugmented # or use any dataset from package

#use this function to filter words, df = dataframe from corpus
summary <- summary[which(is.word(summary$token)),]
```

#3 DTM 

```{r}
summary_dtm <- summary %>% 
   filter(str_length(token) > 1) %>% 
   count(id, year, token) %>% 
   group_by(token) %>% 
   #filter(n() < ) %>% # remove tokens that appear in more than X documents (i.e., years) 
   cast_dtm(document = id, term = token, value = n)
```

#4 Finding k
```{r}

library(ldatuning)

determine_k <- FindTopicsNumber(
   summary_dtm,
   topics = seq(from = 2, to = 60, by = 5),
   metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010", "Deveaud2014"),
   method = "Gibbs",
   control = list(seed = 77),
   mc.cores = 16L,
   verbose = TRUE
 )
```
```{r}
FindTopicsNumber_plot(determine_k)
```


#5 Topic Model
```{r}
library(topicmodels)
library(broom)

summary_dtm_k52 <- LDA(summary_dtm, k = 52, control = list(seed = 77))
saveRDS(summary_dtm_k52, paste0(data_path, "summary_dtm_k52"))

summary_dtm_k52 <- readRDS(paste0(data_path, "summary_dtm_k52"))

summary_dtm_k52_tidied <- tidy(summary_dtm_k52)

#write_rds(sotu_lda_k16, "lda_16.rds")
summary_dtm_k52_tidied %>% glimpse()

top_terms_k52 <- summary_dtm_k52_tidied %>%
   group_by(topic) %>%
   slice_max(beta, n = 10, with_ties = FALSE) %>%
   ungroup() %>%
   arrange(topic, -beta)

tp_k52 <- top_terms_k52 %>%
   mutate(topic = factor(topic),
          term = reorder_within(term, beta, topic)) %>%
   ggplot(aes(term, beta, fill = topic)) +
   geom_bar(stat = "identity", show.legend = FALSE) +
   scale_x_reordered() +
   facet_wrap(~topic, scales = "free", ncol = 4) +
   coord_flip()

ggsave("tp_k52.png", device = "png", plot = tp_k52, path = data_path)

```
